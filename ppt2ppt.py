import os
import io
import copy
import numpy as np
from PIL import Image
import cv2
import math
import statistics
import torch 
import paddle
import traceback
import ssl

# ================= 0. ç¯å¢ƒé…ç½® =================
ssl._create_default_https_context = ssl._create_unverified_context
os.environ["FLAGS_use_mkldnn"] = "0" 
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

# ================= 1. æ˜¾å¡æ£€æŸ¥ =================
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f"ğŸš€ AIä¿®å¤å¼•æ“ (LaMa): {device.upper()}")

if device == 'cpu':
    try:
        _original_torch_load = torch.jit.load
        def _safe_cpu_load(f, map_location=None, _extra_files=None):
            return _original_torch_load(f, map_location=torch.device('cpu'), _extra_files=_extra_files)
        torch.jit.load = _safe_cpu_load
    except: pass

try:
    from simple_lama_inpainting import SimpleLama
    lama_model = SimpleLama()
    HAS_LAMA = True
    print("âœ… LaMa ä¿®å¤æ¨¡å‹åŠ è½½æˆåŠŸ")
except:
    print("âš ï¸ LaMa åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨ OpenCV å¤‡ä»½")
    HAS_LAMA = False

from pdf2image import convert_from_path
from paddleocr import PaddleOCR
from pptx import Presentation
from pptx.util import Pt, Inches
from pptx.dml.color import RGBColor
from pptx.enum.text import MSO_ANCHOR, MSO_AUTO_SIZE, PP_ALIGN
from pptx.enum.shapes import MSO_SHAPE_TYPE

# ================= é…ç½®åŒºåŸŸ =================
POPPLER_PATH = None 
WATERMARK_KEYWORDS = [
    "notebooklm", "generated by", "google", "overview", "briefing", 
    "audio", "summary", "ai overview", "source guide", "listening"
]

FORCED_ERASE_REGIONS = [
    [0.70, 0.88, 1.0, 1.0] 
]

# ä¿æŒ 200 DPI (æ¸…æ™°åº¦ä¸é€Ÿåº¦çš„å¹³è¡¡)
SCAN_DPI = 200

# æå°å­—å·æ”¯æŒ
STANDARD_SIZES = [
    5, 6, 7, 8, 9, 10, 10.5, 11, 12, 13, 14, 15, 16, 18, 
    20, 22, 24, 26, 28, 32, 36, 40
]
# ===========================================

def px_to_inches(px, dpi=72): return px / dpi
def is_mostly_english(text): return (sum(1 for c in text if c.isascii()) / len(text)) > 0.7 if text else False

def snap_to_standard_size(size):
    return min(STANDARD_SIZES, key=lambda x: abs(x - size))

def convert_raw_to_blocks(ocr_data):
    if not ocr_data: return []
    blocks = []
    for line in ocr_data:
        box = line[0]
        text = line[1][0]
        height = box[2][1] - box[0][1]
        width = box[2][0] - box[0][0]
        block = {
            'lines': [text],
            'box': box,
            'avg_height': height,
            'line_widths': [width],
            'sample_box': box,
            'polygons': [box]
        }
        blocks.append(block)
    return blocks

def smart_clean_image_ai(pil_img, blocks_to_clean):
    try:
        w, h = pil_img.size
        mask = np.zeros((h, w), dtype=np.uint8)
        
        for block in blocks_to_clean:
            for poly in block['polygons']: 
                points = np.array(poly, dtype=np.int32)
                cv2.fillPoly(mask, [points], 255)
        
        for region in FORCED_ERASE_REGIONS:
            x1 = int(region[0] * w)
            y1 = int(region[1] * h)
            x2 = int(region[2] * w)
            y2 = int(region[3] * h)
            cv2.rectangle(mask, (x1, y1), (x2, y2), 255, -1)

        kernel_size = 15 
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size, kernel_size))
        mask = cv2.dilate(mask, kernel, iterations=1)
        mask_feathered = cv2.GaussianBlur(mask, (21, 21), 11)
        
        if HAS_LAMA:
            try:
                return lama_model(pil_img, Image.fromarray(mask_feathered))
            except RuntimeError:
                # æ˜¾å­˜ä¸è¶³æ—¶è‡ªåŠ¨å›é€€
                torch.cuda.empty_cache()
                img_np = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
                res_cv = cv2.inpaint(img_np, mask, 5, cv2.INPAINT_TELEA)
                return Image.fromarray(cv2.cvtColor(res_cv, cv2.COLOR_BGR2RGB))
        else:
            img_np = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
            res_cv = cv2.inpaint(img_np, mask, 5, cv2.INPAINT_TELEA)
            return Image.fromarray(cv2.cvtColor(res_cv, cv2.COLOR_BGR2RGB))
    except Exception as e:
        print(f"âš ï¸ ä¿®å¤æµç¨‹å‡ºé”™: {e}")
        return pil_img

def get_text_color_kmeans(pil_image, box):
    try:
        roi = np.array(pil_image)[int(max(0, box[0][1])):int(min(pil_image.size[1], box[2][1])), int(max(0, box[0][0])):int(min(pil_image.size[0], box[2][0]))]
        if roi.size == 0: return RGBColor(0,0,0)
        pixels = roi.reshape((-1, 3)).astype(np.float32)
        _, labels, centers = cv2.kmeans(pixels, 2, None, (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0), 10, cv2.KMEANS_RANDOM_CENTERS)
        unique, counts = np.unique(labels, return_counts=True)
        indices = np.argsort(counts)[::-1] 
        bg_color = centers[indices[0]] 
        fg_color = centers[indices[1]] if len(indices) > 1 else bg_color 
        def get_lum(c): return 0.299*c[0] + 0.587*c[1] + 0.114*c[2]
        bg_lum, fg_lum = get_lum(bg_color), get_lum(fg_color)
        if bg_lum > 200: final = fg_color if fg_lum < bg_lum else bg_color
        elif bg_lum < 50: final = fg_color if fg_lum > bg_lum else bg_color
        else: final = fg_color
        if get_lum(final) > 230: return RGBColor(0, 0, 0)
        return RGBColor(int(final[0]), int(final[1]), int(final[2]))
    except: return RGBColor(0,0,0)

# ã€æ ¸å¿ƒå‡çº§ã€‘æ™ºèƒ½é‡è¯•æœºåˆ¶
def process_single_image_content(pil_img, ocr_engine):
    try:
        # 1. ç¬¬ä¸€æ¬¡å°è¯•ï¼šåŸå›¾è¯†åˆ«
        result = ocr_engine.ocr(np.array(pil_img), cls=True)
        
        # 2. å¦‚æœè¯†åˆ«ç»“æœä¸ºç©ºï¼ˆæ¼é¡µï¼‰ï¼Œå°è¯•ç¼©å°å›¾ç‰‡é‡è¯•
        if result is None or len(result) == 0 or result[0] is None:
            print("   âš ï¸ åˆæ¬¡è¯†åˆ«ä¸ºç©ºï¼Œæ­£åœ¨å°è¯•ã€é™ç»´é‡æ‰«ã€‘...")
            # ç¼©å°åˆ° 80% å†è¯•ä¸€æ¬¡ï¼Œæœ‰æ—¶å€™å°ä¸€ç‚¹åè€Œèƒ½è¯†åˆ«åˆ°æ•´ä½“
            w, h = pil_img.size
            small_img = pil_img.resize((int(w*0.8), int(h*0.8)), Image.LANCZOS)
            result_retry = ocr_engine.ocr(np.array(small_img), cls=True)
            
            if result_retry and len(result_retry) > 0 and result_retry[0]:
                print(f"   âœ… é‡è¯•æˆåŠŸï¼æ‰¾å› {len(result_retry[0])} è¡Œæ–‡å­—")
                # åæ ‡è¿˜åŸæ¯”ä¾‹
                scale_recover = 1.0 / 0.8
                restored_data = []
                for line in result_retry[0]:
                    box = np.array(line[0]) * scale_recover
                    restored_data.append([box.tolist(), line[1]])
                result = [restored_data]
            else:
                print("   âŒ é‡è¯•ä»æœªè¯†åˆ«åˆ°æ–‡å­—ï¼Œä¿ç•™èƒŒæ™¯å›¾")
                return None, []

        text_data = []
        for line in result[0]:
            if not line or len(line) < 2: continue
            text_content = line[1][0]
            if not isinstance(text_content, str): continue 
            
            is_watermark = False
            for kw in WATERMARK_KEYWORDS:
                if kw in text_content.lower():
                    is_watermark = True
                    break
            # æçŸ­å­—ç¬¦æ”¾è¡Œï¼Œé˜²æ­¢æ¼æ‰é¡µç 
            if len(text_content) < 2 and not text_content.isdigit() and not text_content.isalpha(): 
                is_watermark = True

            if not is_watermark:
                text_data.append(line)
        
        merged_blocks = convert_raw_to_blocks(text_data)
        clean_bg = smart_clean_image_ai(pil_img, merged_blocks)
        return clean_bg, merged_blocks
    except Exception as e: 
        print(f"   âŒ OCR å¤„ç†å¼‚å¸¸: {e}")
        return None, []

def calculate_unified_font_sizes(blocks, scale_y):
    if not blocks: return []
    
    raw_sizes = []
    for block in blocks:
        text = block['lines'][0]
        is_en = is_mostly_english(text)
        
        box_h_px = block['avg_height']
        physical_height_pt = (box_h_px * scale_y) * (72 / SCAN_DPI)
        
        # ç²¾è‡´å°å­—ç³»æ•°
        fill_ratio = 0.50 if is_en else 0.55
        
        calculated_size = physical_height_pt * fill_ratio
        block['temp_size'] = calculated_size
        raw_sizes.append(calculated_size)
    
    if not raw_sizes: return blocks

    median_size = statistics.median(raw_sizes)
    
    for block in blocks:
        current = block['temp_size']
        if 0.8 * median_size <= current <= 1.2 * median_size:
            final_size = median_size
        else:
            final_size = current
            
        block['final_font_pt'] = snap_to_standard_size(final_size)
        text = block['lines'][0]
        block['font_name'] = 'Arial' if is_mostly_english(text) else 'Microsoft YaHei'
        
    return blocks

def create_text_boxes_on_slide(slide, merged_blocks, original_img, prs, offset_x=0, offset_y=0, scale_x=1.0, scale_y=1.0):
    prs_width_inches = prs.slide_width.inches
    if hasattr(offset_x, "inches"): off_x_val = offset_x.inches
    else: off_x_val = 0
    
    blocks_with_font = calculate_unified_font_sizes(merged_blocks, scale_y)
    
    for block in blocks_with_font:
        box, lines = block['box'], block['lines']
        full_text = lines[0] 
        
        left_inch = px_to_inches(box[0][0] * scale_x, SCAN_DPI)
        top_inch = px_to_inches(box[0][1] * scale_y, SCAN_DPI)
        
        box_w_px = box[2][0] - box[0][0]
        box_h_px = box[2][1] - box[0][1]
        
        width_inch = px_to_inches(box_w_px * scale_x, SCAN_DPI) * 1.05
        height_inch = px_to_inches(box_h_px * scale_y, SCAN_DPI)
        
        if off_x_val + left_inch + width_inch > prs_width_inches:
            width_inch = prs_width_inches - (off_x_val + left_inch) - 0.1

        txBox = slide.shapes.add_textbox(offset_x + Inches(left_inch), offset_y + Inches(top_inch), Inches(width_inch), Inches(height_inch))
        tf = txBox.text_frame
        tf.word_wrap = False 
        tf.auto_size = MSO_AUTO_SIZE.NONE
        tf.vertical_anchor = MSO_ANCHOR.MIDDLE 
        
        tf.margin_left = tf.margin_right = 0
        tf.margin_top = tf.margin_bottom = 0
        
        p = tf.paragraphs[0]
        p.text = full_text
        p.font.size = Pt(max(5, block['final_font_pt'])) 
        p.font.name = block['font_name']
        p.font.color.rgb = get_text_color_kmeans(original_img, block['sample_box'])
        p.line_spacing = 1.0 

def iter_picture_shapes(shapes, parent_offset=(0,0)):
    for shape in shapes:
        l, t = parent_offset[0] + shape.left, parent_offset[1] + shape.top
        if shape.shape_type == MSO_SHAPE_TYPE.GROUP: yield from iter_picture_shapes(shape.shapes, (l, t))
        elif shape.shape_type in [MSO_SHAPE_TYPE.PICTURE, MSO_SHAPE_TYPE.PLACEHOLDER] and hasattr(shape, 'image'): yield (shape, l, t)

def process_pdf_file(pdf_path, output_ppt_path, ocr_engine):
    print(f"--- PDF æ¨¡å¼ (V19: è‡ªé€‚åº”é˜²æ¼é¡µ) ---")
    try: 
        # ä¿æŒ 200 DPI
        images = convert_from_path(pdf_path, dpi=SCAN_DPI, poppler_path=POPPLER_PATH)
    except Exception as e: return print(f"âŒ PDF è¯»å–å¤±è´¥: {e}")
    
    prs = Presentation()
    if images:
        w_px, h_px = images[0].width, images[0].height
        prs.slide_width = Inches(px_to_inches(w_px, SCAN_DPI))
        prs.slide_height = Inches(px_to_inches(h_px, SCAN_DPI))

    for i, img in enumerate(images):
        print(f"ğŸ“„ å¤„ç†ç¬¬ {i+1}/{len(images)} é¡µ...")
        slide = prs.slides.add_slide(prs.slide_layouts[6])
        try:
            clean_bg, blocks = process_single_image_content(img, ocr_engine)
            final_bg = clean_bg if clean_bg else img
            bg_stream = io.BytesIO()
            final_bg.save(bg_stream, format='JPEG')
            bg_stream.seek(0)
            slide.shapes.add_picture(bg_stream, 0, 0, width=prs.slide_width, height=prs.slide_height)
            if blocks: create_text_boxes_on_slide(slide, blocks, img, prs)
            else: print("   âš ï¸ æœ¬é¡µæœªæå–åˆ°æ–‡å­—ï¼Œä»…ä¿ç•™èƒŒæ™¯")
        except Exception as e:
            print(f"   [Error] æœ¬é¡µå‡ºé”™: {e}")
            traceback.print_exc()
    prs.save(output_ppt_path)
    print(f"ğŸ‰ å®Œæˆ: {output_ppt_path}")

def process_pptx_file(input_pptx, output_pptx, ocr_engine):
    print(f"--- PPTX æ¨¡å¼ (V19: è‡ªé€‚åº”é˜²æ¼é¡µ) ---")
    prs = Presentation(input_pptx)
    for i, slide in enumerate(prs.slides):
        print(f"æ­£åœ¨å¤„ç†ç¬¬ {i + 1} é¡µ...")
        for shape, l, t in list(iter_picture_shapes(slide.shapes)):
            try:
                img_pil = Image.open(io.BytesIO(shape.image.blob))
                clean_bg, blocks = process_single_image_content(img_pil, ocr_engine)
                bg_stream = io.BytesIO()
                final_bg = clean_bg if clean_bg else img_pil
                final_bg.save(bg_stream, format='PNG')
                bg_stream.seek(0)
                slide.shapes.add_picture(bg_stream, l, t, shape.width, shape.height)
                if blocks:
                    create_text_boxes_on_slide(slide, blocks, img_pil, prs, offset_x=l, offset_y=t, scale_x=(shape.width/914400)/(img_pil.width/SCAN_DPI), scale_y=(shape.width/914400)/(img_pil.width/SCAN_DPI))
                shape.left = Inches(-20)
            except Exception as e: print(f"   [Error] {e}")
    prs.save(output_pptx)
    print(f"ğŸ‰ å®Œæˆ: {output_pptx}")

def main():
    input_file = "test.pdf" 
    output_file = "final_v19.pptx"
    
    if not os.path.exists(input_file): return print(f"âŒ æ‰¾ä¸åˆ° {input_file}")

    print("æ­£åœ¨åˆå§‹åŒ– OCR (CPUç¨³å®šæ¨¡å¼)...")
    try:
        paddle.set_device('cpu') 
        ocr_engine = PaddleOCR(
            lang="ch", 
            use_angle_cls=True,   
            enable_mkldnn=False,  
            use_mp=False,
            # ã€æ ¸å¿ƒä¿®å¤ã€‘æå‡æ£€æµ‹è¾¹é•¿é™åˆ¶ï¼Œé˜²æ­¢å¤§å›¾è¢«ç¼©å°å¯¼è‡´æ¼å­—
            det_limit_side_len=2500, # ä» 1600 æå‡åˆ° 2500ï¼Œé€‚é… A4@200DPI
            det_db_thresh=0.08,      
            det_db_box_thresh=0.2,   
            det_db_unclip_ratio=2.5, 
            use_dilation=True        
        )
        print("âœ… åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        return

    ext = os.path.splitext(input_file)[1].lower()
    if ext == ".pdf": process_pdf_file(input_file, output_file, ocr_engine)
    elif ext in [".pptx", ".ppt"]: process_pptx_file(input_file, output_file, ocr_engine)
    else: print("ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼")

if __name__ == "__main__":
    main()